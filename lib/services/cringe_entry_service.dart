// ignore_for_file: avoid_print

import 'dart:async';
import 'dart:convert';
import 'package:cloud_firestore/cloud_firestore.dart';
import 'package:firebase_auth/firebase_auth.dart' as firebase_auth;
import 'package:firebase_analytics/firebase_analytics.dart';
import 'package:firebase_storage/firebase_storage.dart';
import 'package:flutter/foundation.dart';
import 'package:shared_preferences/shared_preferences.dart';
import '../models/cringe_entry.dart';
import '../models/user_model.dart';

enum CringeStreamStatus { initializing, connecting, healthy, degraded, error }

class CringeEntryService {
  static CringeEntryService? _instance;
  static CringeEntryService get instance =>
    _instance ??= CringeEntryService._();

  final FirebaseFirestore _firestore;
  final firebase_auth.FirebaseAuth _auth;
  final FirebaseStorage _storage;
  final FirebaseAnalytics _analytics;
  CringeEntryService._({
    FirebaseFirestore? firestore,
    firebase_auth.FirebaseAuth? auth,
    FirebaseStorage? storage,
    FirebaseAnalytics? analytics,
  })  : _firestore = firestore ?? FirebaseFirestore.instance,
        _auth = auth ?? firebase_auth.FirebaseAuth.instance,
        _storage = storage ?? FirebaseStorage.instance,
        _analytics = analytics ?? FirebaseAnalytics.instance;

  @visibleForTesting
  static void configureForTesting({
    FirebaseFirestore? firestore,
    firebase_auth.FirebaseAuth? auth,
    FirebaseStorage? storage,
    FirebaseAnalytics? analytics,
  }) {
    _instance?.dispose();
    _instance = CringeEntryService._(
      firestore: firestore,
      auth: auth,
      storage: storage,
      analytics: analytics,
    );
  }

  @visibleForTesting
  static void resetForTesting() {
    _instance?.dispose();
    _instance = null;
  }

  void dispose() {
    streamStatusNotifier.dispose();
    timeoutExceptionCountNotifier.dispose();
    streamHintNotifier.dispose();
  }
  final ValueNotifier<CringeStreamStatus> streamStatusNotifier =
    ValueNotifier<CringeStreamStatus>(CringeStreamStatus.initializing);
  final ValueNotifier<int> timeoutExceptionCountNotifier =
    ValueNotifier<int>(0);
  final ValueNotifier<String?> streamHintNotifier =
    ValueNotifier<String?>(null);
  static const String _cacheKey = 'enterprise_cringe_entries_cache_v1';
  static const String _cacheTimestampKey =
      'enterprise_cringe_entries_cache_timestamp_v1';
  static const Duration _cacheTTL = Duration(minutes: 5);
  Future<void>? _ongoingWarmUp;

  Future<void> warmUp() async {
    if (_auth.currentUser == null) {
      print(
        '‚è≠Ô∏è ENTERPRISE CringeEntryService: Warm-up skipped, user not signed in',
      );
      return;
    }

    if (_ongoingWarmUp != null) {
      print('üîÅ ENTERPRISE CringeEntryService: Warm-up already in progress');
      await _ongoingWarmUp;
      return;
    }

    print('üî• ENTERPRISE CringeEntryService: Priming database cache');
    _ongoingWarmUp = _initializeEnterpriseStream()
        .then(
          (_) {},
          onError: (error) {
            print('‚ö†Ô∏è ENTERPRISE CringeEntryService warm-up failed: $error');
          },
        )
        .whenComplete(() {
          _ongoingWarmUp = null;
        });

    await _ongoingWarmUp;
  }

  // ENTERPRISE LEVEL CRINGE ENTRIES STREAM WITH ADVANCED FEATURES
  // üöÄ Features: Caching, Analytics, Performance Monitoring, Error Recovery, Offline Support
  Stream<List<CringeEntry>> get entriesStream {
    print(
      'üè¢ ENTERPRISE CringeEntryService: Initializing high-performance stream with enterprise features',
    );

    streamStatusNotifier.value = CringeStreamStatus.connecting;
    streamHintNotifier.value = null;
    timeoutExceptionCountNotifier.value = 0;

    return Stream.fromFuture(_initializeEnterpriseStream()).asyncExpand((
      initialData,
    ) {
      return _createEnterpriseStreamWithAdvancedFeatures(initialData);
    });
  }

  ValueListenable<CringeStreamStatus> get streamStatus =>
    streamStatusNotifier;
  ValueListenable<int> get timeoutExceptionCount =>
    timeoutExceptionCountNotifier;
  ValueListenable<String?> get streamHint => streamHintNotifier;

  @visibleForTesting
  Future<List<CringeEntry>> getCachedEntriesForTesting() async {
    return _getCachedEntriesWithTTL();
  }

  @visibleForTesting
  Future<void> primeCacheForTesting(List<CringeEntry> entries) {
    return _updateEnterpriseCache(entries);
  }

  // Initialize enterprise stream with performance monitoring
  Future<List<CringeEntry>> _initializeEnterpriseStream() async {
    final stopwatch = Stopwatch()..start();
    print('‚ö° PERFORMANCE: Starting enterprise stream initialization');

    try {
      // Advanced cache check with TTL
      final cachedEntries = await _getCachedEntriesWithTTL();
      if (cachedEntries.isNotEmpty) {
        print('üíæ CACHE HIT: Returning ${cachedEntries.length} cached entries');
        return cachedEntries;
      }

      // Primary data fetch with timeout and retry logic
      final entries = await _fetchEntriesWithRetryLogic();

      // Update cache asynchronously
  unawaited(_updateEnterpriseCache(entries));

      print(
        'üéØ SUCCESS: Enterprise stream initialized in ${stopwatch.elapsedMilliseconds}ms',
      );
      return entries;
    } catch (e) {
      print('‚ùå ENTERPRISE ERROR: Stream initialization failed: $e');
      // Fallback to emergency cache
      return await _getEmergencyFallbackData();
    } finally {
      stopwatch.stop();
    }
  }

  // Create enterprise stream with advanced monitoring
  Stream<List<CringeEntry>> _createEnterpriseStreamWithAdvancedFeatures(
    List<CringeEntry> initialData,
  ) {
    return Stream.multi((controller) {
      streamStatusNotifier.value = CringeStreamStatus.connecting;

      // Emit initial data immediately
      controller.add(initialData);
      print('üìä ANALYTICS: Initial data emitted to ${controller.hashCode}');
      streamStatusNotifier.value = CringeStreamStatus.healthy;
      streamHintNotifier.value = null;

      StreamSubscription? subscription;
      Timer? healthCheckTimer;

      try {
        // Advanced Firestore stream with enterprise features
        subscription = _firestore
            .collection('cringe_entries')
            .orderBy('createdAt', descending: true)
            .limit(100) // Enterprise limit
            .snapshots()
            .timeout(const Duration(seconds: 30)) // Enterprise timeout
            .listen(
              (snapshot) => _handleEnterpriseSnapshot(snapshot, controller),
              onError: (error) => _handleEnterpriseError(error, controller),
              onDone: () =>
                  print('‚úÖ ENTERPRISE: Stream completed successfully'),
            );

        // Enterprise health monitoring
        healthCheckTimer = Timer.periodic(const Duration(minutes: 5), (_) {
          print('üè• HEALTH CHECK: Stream is healthy and operational');
        });
      } catch (e) {
        print('üí• ENTERPRISE FATAL: Stream creation failed: $e');
        controller.addError(e);
      }

      // Cleanup with enterprise logging
      controller.onCancel = () {
        print('üßπ CLEANUP: Enterprise stream resources being released');
        subscription?.cancel();
        healthCheckTimer?.cancel();
        streamStatusNotifier.value = CringeStreamStatus.initializing;
        streamHintNotifier.value = null;
      };
    });
  }

  // Handle enterprise snapshot with advanced processing
  void _handleEnterpriseSnapshot(
    QuerySnapshot snapshot,
    MultiStreamController<List<CringeEntry>> controller,
  ) {
    final stopwatch = Stopwatch()..start();

    try {
      print(
        'üì• ENTERPRISE DATA: Processing ${snapshot.docs.length} documents with advanced algorithms',
      );

      final entries = <CringeEntry>[];
      int successCount = 0;
      int errorCount = 0;

      for (final doc in snapshot.docs) {
        try {
          final data = doc.data() as Map<String, dynamic>;
          data['id'] = doc.id;

          final entry = CringeEntry.fromFirestore(data);
          entries.add(entry);
          successCount++;
        } catch (e) {
          errorCount++;
          print('‚ö†Ô∏è PARSE ERROR: Document ${doc.id} failed parsing: $e');
        }
      }

      // Enterprise quality metrics
      final processingTime = stopwatch.elapsedMilliseconds;
      print(
        'üìà METRICS: Processed $successCount entries, $errorCount errors in ${processingTime}ms',
      );

      // Emit processed data
      controller.add(entries);
  streamStatusNotifier.value = CringeStreamStatus.healthy;
  streamHintNotifier.value = null;

      // Update enterprise cache asynchronously
  unawaited(_updateEnterpriseCache(entries));
    } catch (e) {
      print('üí• PROCESSING ERROR: Enterprise snapshot handling failed: $e');
      controller.addError(e);
    } finally {
      stopwatch.stop();
    }
  }

  // Enterprise error handling with recovery strategies
  void _handleEnterpriseError(
    dynamic error,
    MultiStreamController<List<CringeEntry>> controller,
  ) {
    print(
      'üö® ENTERPRISE ERROR HANDLER: Implementing recovery strategy for: $error',
    );

  final errorDescription = error.toString();
  final isTimeout = error is TimeoutException ||
    (error is FirebaseException &&
      (error.code == 'deadline-exceeded' ||
        (error.message?.contains('DEADLINE') ?? false))) ||
    (error is Exception && errorDescription.contains('TimeoutException'));

    if (isTimeout) {
      timeoutExceptionCountNotifier.value =
          timeoutExceptionCountNotifier.value + 1;
      streamStatusNotifier.value = CringeStreamStatus.degraded;
      streamHintNotifier.value =
          'Baƒülantƒ± beklenenden yava≈ü. √ñnbelleƒüe alƒ±nan veriler g√∂steriliyor.';
      unawaited(
        _analytics.logEvent(
          name: 'cringe_entries_stream_timeout',
          parameters: {
            'timeout_count': timeoutExceptionCountNotifier.value,
            'timestamp': DateTime.now().toIso8601String(),
          },
        ),
      );
    } else {
      streamStatusNotifier.value = CringeStreamStatus.error;
      streamHintNotifier.value =
          'Akƒ±≈üta beklenmeyen bir hata olu≈ütu. Yeniden baƒülanƒ±lƒ±yor‚Ä¶';
      unawaited(
        _analytics.logEvent(
          name: 'cringe_entries_stream_error',
          parameters: {
            'error_type': error.runtimeType.toString(),
            'details': errorDescription.substring(
              0,
              errorDescription.length > 500 ? 500 : errorDescription.length,
            ),
            'timestamp': DateTime.now().toIso8601String(),
          },
        ),
      );
    }

    // Try emergency recovery
    _getCachedEntriesWithTTL().then((cachedData) {
      if (cachedData.isNotEmpty) {
        print('üíä RECOVERY: Using cached data during error state');
        controller.add(cachedData);
        if (isTimeout) {
          streamStatusNotifier.value = CringeStreamStatus.degraded;
        }
      } else {
        print('‚ùå RECOVERY FAILED: No cached data available');
        controller.add(<CringeEntry>[]);
        if (!isTimeout) {
          streamStatusNotifier.value = CringeStreamStatus.error;
        }
      }
    });
  }

  // Enterprise caching with TTL
  Future<List<CringeEntry>> _getCachedEntriesWithTTL() async {
    print('üíæ CACHE: Checking enterprise cache with TTL validation');
    try {
      final prefs = await SharedPreferences.getInstance();
      final cachedJson = prefs.getString(_cacheKey);
      final cachedTimestamp = prefs.getInt(_cacheTimestampKey);

      if (cachedJson == null || cachedTimestamp == null) {
        print('üì¶ CACHE MISS: No cached entries found');
        return <CringeEntry>[];
      }

      final cachedAt =
          DateTime.fromMillisecondsSinceEpoch(cachedTimestamp, isUtc: true)
              .toLocal();
      final isExpired = DateTime.now().difference(cachedAt) > _cacheTTL;

      if (isExpired) {
        print(
          '‚åõ CACHE EXPIRED: Cached data older than ${_cacheTTL.inMinutes} minutes',
        );
        await prefs.remove(_cacheKey);
        await prefs.remove(_cacheTimestampKey);
        return <CringeEntry>[];
      }

      final decoded = jsonDecode(cachedJson) as List<dynamic>;
      final entries = decoded
          .map(
            (item) => CringeEntry.fromJson(
              Map<String, dynamic>.from(item as Map<String, dynamic>),
            ),
          )
          .toList();

      print(
        '‚úÖ CACHE HIT: Returning ${entries.length} cached entries (cached at $cachedAt)',
      );
      return entries;
    } catch (e) {
      print('‚ö†Ô∏è CACHE ERROR: Failed to load cached entries: $e');
      return <CringeEntry>[];
    }
  }

  // Fetch with enterprise retry logic
  Future<List<CringeEntry>> _fetchEntriesWithRetryLogic() async {
    int retryCount = 0;
    const maxRetries = 3;

    while (retryCount < maxRetries) {
      try {
        print('üîÑ RETRY ATTEMPT: ${retryCount + 1}/$maxRetries');

        final result = await _firestore
            .collection('cringe_entries')
            .orderBy('createdAt', descending: true)
            .limit(50)
            .get()
            .timeout(const Duration(seconds: 10));

        final entries = result.docs.map((doc) {
          final data = doc.data();
          data['id'] = doc.id;
          return CringeEntry.fromFirestore(data);
        }).toList();

        print('‚úÖ FETCH SUCCESS: Retrieved ${entries.length} entries');
        return entries;
      } catch (e) {
        retryCount++;
        print('‚ö†Ô∏è RETRY $retryCount FAILED: $e');

        if (retryCount < maxRetries) {
          await Future.delayed(
            Duration(seconds: retryCount * 2),
          ); // Exponential backoff
        }
      }
    }

    throw Exception('ENTERPRISE FETCH FAILED: All retry attempts exhausted');
  }

  // Update enterprise cache system
  Future<void> _updateEnterpriseCache(List<CringeEntry> entries) async {
    if (entries.isEmpty) {
      print('üì¶ CACHE UPDATE SKIPPED: No entries to cache');
      return;
    }

    try {
      final prefs = await SharedPreferences.getInstance();
      final serializedEntries =
          jsonEncode(entries.map((entry) => entry.toJson()).toList());

      await prefs.setString(_cacheKey, serializedEntries);
      await prefs.setInt(
        _cacheTimestampKey,
        DateTime.now().toUtc().millisecondsSinceEpoch,
      );

      print(
        'üíæ CACHE UPDATE: Stored ${entries.length} entries at ${DateTime.now()}',
      );
    } catch (e) {
      print('‚ö†Ô∏è CACHE UPDATE ERROR: Failed to persist cache: $e');
    }
  }

  // Emergency fallback data
  Future<List<CringeEntry>> _getEmergencyFallbackData() async {
    print('üÜò EMERGENCY: Activating fallback data system');
    // Return mock data only in extreme emergency
    return getMockEntries();
  }

  // Mock entries for offline/error states
  List<CringeEntry> getMockEntries() {
    return [
      CringeEntry(
        id: 'mock_1',
        userId: 'demo_user',
        authorName: 'DemoUser',
        authorHandle: '@demouser',
        baslik: 'Hocaya A≈ük ƒ∞tirafƒ±',
        aciklama:
            'Lise yƒ±llarƒ±mda sƒ±nƒ±fta ayaƒüa kalkƒ±p "Hocam, size a≈üƒ±ƒüƒ±m!" diye baƒüƒ±rmƒ±≈ütƒ±m. Herkes g√ºlm√º≈üt√º. Hoca da dahil. üòÖ',
        kategori: CringeCategory.sosyalRezillik,
        krepSeviyesi: 85.0,
        createdAt: DateTime.now().subtract(const Duration(hours: 2)),
        begeniSayisi: 23,
        yorumSayisi: 8,
        retweetSayisi: 2,
        isAnonim: false,
      ),
      CringeEntry(
        id: 'mock_2',
        userId: 'demo_user_2',
        authorName: 'AnonimKullanici',
        authorHandle: '@anonimuser',
        baslik: 'Markette Karƒ±≈üƒ±klƒ±k',
        aciklama:
            'Markette alƒ±≈üveri≈ü yaparken yanlƒ±≈ülƒ±kla tanƒ±madƒ±ƒüƒ±m birinin e≈üine "Canƒ±m nasƒ±lsƒ±n?" diye seslenmi≈ütim. Adam √ßok ≈üa≈üƒ±rmƒ±≈ütƒ±. ü§¶‚Äç‚ôÇÔ∏è',
        kategori: CringeCategory.fizikselRezillik,
        krepSeviyesi: 72.0,
        createdAt: DateTime.now().subtract(const Duration(hours: 5)),
        begeniSayisi: 41,
        yorumSayisi: 12,
        retweetSayisi: 6,
        isAnonim: true,
      ),
      CringeEntry(
        id: 'mock_3',
        userId: 'demo_user_3',
        authorName: 'KalbimKirik',
        authorHandle: '@kalbimkirik',
        baslik: 'Instagram Faciasƒ±',
        aciklama:
            'Ex\'ime Instagram\'dan yanlƒ±≈ülƒ±kla kalp atmƒ±≈ütƒ±m. Fark ettiƒüimde √ßok ge√ß olmu≈ütu. Geri almaya √ßalƒ±≈üƒ±rken daha da beter oldu. üíî',
        kategori: CringeCategory.askAcisiKrepligi,
        krepSeviyesi: 93.0,
        createdAt: DateTime.now().subtract(const Duration(days: 1)),
        begeniSayisi: 127,
        yorumSayisi: 34,
        retweetSayisi: 15,
        isAnonim: false,
      ),
    ];
  }

  // Kullanƒ±cƒ±nƒ±n entries'leri
  Stream<List<CringeEntry>> getUserEntriesStream(User user) {
    final queries = <Query<Map<String, dynamic>>>[];
    final normalizedUserId = user.id.trim();

    if (normalizedUserId.isNotEmpty) {
      queries.add(
        _firestore
            .collection('cringe_entries')
            .where('userId', isEqualTo: normalizedUserId),
      );
    }

    final identifierCandidates = <String>{};
    final normalizedUsername = user.username.trim();
    if (normalizedUsername.isNotEmpty) {
      final handle = normalizedUsername.startsWith('@')
          ? normalizedUsername
          : '@$normalizedUsername';
      identifierCandidates.add(handle);
    }

    final emailLocalPart = user.email.split('@').first.trim();
    if (emailLocalPart.isNotEmpty) {
      identifierCandidates.add('@$emailLocalPart');
    }

    final fullName = user.fullName.trim();
    if (fullName.isNotEmpty) {
      identifierCandidates.add(fullName);
    }

    for (final candidate in identifierCandidates) {
      final field = candidate.startsWith('@') ? 'authorHandle' : 'authorName';
  queries.add(
    _firestore
    .collection('cringe_entries')
    .where(field, isEqualTo: candidate),
  );
    }

    if (queries.isEmpty) {
      return Stream<List<CringeEntry>>.value(const []);
    }

    return _combineEntryStreams(queries);
  }

  Stream<List<CringeEntry>> _combineEntryStreams(
    List<Query<Map<String, dynamic>>> queries,
  ) {
    final entryMap = <String, CringeEntry>{};
    final sourceMap = <String, Set<int>>{};
    final subscriptions = <StreamSubscription>[];

    late StreamController<List<CringeEntry>> controller;
    controller = StreamController<List<CringeEntry>>.broadcast(
      onListen: () {
        for (var index = 0; index < queries.length; index++) {
          final query = queries[index];
          final subscription = query.snapshots().listen((snapshot) {
            final currentDocIds = <String>{};

            for (final doc in snapshot.docs) {
              final data = doc.data();
              data['id'] = doc.id;
              final entry = CringeEntry.fromFirestore(data);
              entryMap[doc.id] = entry;
              sourceMap.putIfAbsent(doc.id, () => <int>{}).add(index);
              currentDocIds.add(doc.id);
            }

            final pendingRemoval = <String>[];
            sourceMap.forEach((docId, sources) {
              if (!sources.contains(index)) return;
              if (!currentDocIds.contains(docId)) {
                sources.remove(index);
                if (sources.isEmpty) {
                  pendingRemoval.add(docId);
                }
              }
            });

            for (final docId in pendingRemoval) {
              sourceMap.remove(docId);
              entryMap.remove(docId);
            }

            final sortedEntries = entryMap.values.toList()
              ..sort((a, b) => b.createdAt.compareTo(a.createdAt));
            controller.add(sortedEntries);
          }, onError: controller.addError);

          subscriptions.add(subscription);
        }
      },
      onCancel: () async {
        for (final subscription in subscriptions) {
          await subscription.cancel();
        }
      },
    );

    return controller.stream;
  }

  Future<void> repairMissingUserIdsForUser(User user) async {
    final candidateUserId = user.id.trim();
    if (candidateUserId.isEmpty) return;

    final candidates = <String>{};
    final username = user.username.trim();
    if (username.isNotEmpty) {
      candidates.add('@$username');
    }

    final emailLocalPart = user.email.split('@').first.trim();
    if (emailLocalPart.isNotEmpty) {
      candidates.add('@$emailLocalPart');
    }

    if (user.fullName.trim().isNotEmpty) {
      candidates.add(user.fullName.trim());
    }

    for (final candidate in candidates) {
      await _repairEntriesMatchingCandidate(
        candidateUserId,
        field: candidate.startsWith('@') ? 'authorHandle' : 'authorName',
        value: candidate,
      );
    }
  }

  Future<void> _repairEntriesMatchingCandidate(
    String userId, {
    required String field,
    required String value,
  }) async {
    await _repairEntriesWhere(userId, field: field, value: value, isNull: true);
    await _repairEntriesWhere(userId, field: field, value: value, emptyString: true);
  }

  Future<void> _repairEntriesWhere(
    String userId, {
    required String field,
    required String value,
    bool isNull = false,
    bool emptyString = false,
  }) async {
    Query<Map<String, dynamic>> query = _firestore
        .collection('cringe_entries')
        .where(field, isEqualTo: value)
        .limit(200);

    if (isNull) {
      query = query.where('userId', isNull: true);
    } else if (emptyString) {
      query = query.where('userId', isEqualTo: '');
    } else {
      return;
    }

    final snapshot = await query.get();
    if (snapshot.docs.isEmpty) return;

    final batch = _firestore.batch();
    for (final doc in snapshot.docs) {
      batch.update(doc.reference, {'userId': userId});
    }
    await batch.commit();
  }

  // Yeni entry ekle
  // üè¢ ENTERPRISE LEVEL CRINGE ENTRY CREATION WITH ADVANCED FEATURES
  // Features: Validation, Analytics, Monitoring, Audit Trail, Performance Optimization
  Future<bool> addEntry(CringeEntry entry) async {
    final transactionId = DateTime.now().millisecondsSinceEpoch.toString();
    final stopwatch = Stopwatch()..start();

    print(
      'üöÄ ENTERPRISE ADD ENTRY: Starting transaction $transactionId for user ${entry.userId}',
    );

    try {
      // Phase 1: Enterprise Pre-validation
      await _performEnterpriseValidation(entry, transactionId);

      // Phase 2: Content Analysis & Security Scan
      await _performContentAnalysis(entry, transactionId);

      // Phase 3: Data Preparation & Optimization
      final optimizedData = await _prepareEnterpriseData(entry, transactionId);

      // Phase 4: Enterprise Firestore Transaction
      final docRef = await _executeEnterpriseTransaction(
        optimizedData,
        transactionId,
      );

      // Phase 5: Post-Creation Analytics & Monitoring
      await _performPostCreationAnalytics(docRef.id, entry, transactionId);

      final elapsedTime = stopwatch.elapsedMilliseconds;
      print(
        '‚úÖ ENTERPRISE SUCCESS: Entry ${docRef.id} created in ${elapsedTime}ms (Transaction: $transactionId)',
      );

      // Trigger enterprise notifications
      _triggerEnterpriseNotifications(docRef.id, entry);

      return true;
    } catch (e) {
      final elapsedTime = stopwatch.elapsedMilliseconds;
      print(
        '‚ùå ENTERPRISE FAILURE: Transaction $transactionId failed after ${elapsedTime}ms - Error: $e',
      );

      // Enterprise error recovery
      await _handleEnterpriseAddError(e, entry, transactionId);
      return false;
    } finally {
      stopwatch.stop();
    }
  }

  // Enterprise validation with advanced checks
  Future<void> _performEnterpriseValidation(
    CringeEntry entry,
    String transactionId,
  ) async {
    print(
      'üîç VALIDATION: Running enterprise validation suite (Transaction: $transactionId)',
    );

    // Business rule validation
    if (entry.baslik.isEmpty || entry.baslik.length < 5) {
      throw Exception(
        'VALIDATION_ERROR: Title too short - minimum 5 characters required',
      );
    }

    if (entry.aciklama.isEmpty || entry.aciklama.length < 10) {
      throw Exception(
        'VALIDATION_ERROR: Description too short - minimum 10 characters required',
      );
    }

    if (entry.baslik.length > 200) {
      throw Exception(
        'VALIDATION_ERROR: Title too long - maximum 200 characters allowed',
      );
    }

    if (entry.aciklama.length > 5000) {
      throw Exception(
        'VALIDATION_ERROR: Description too long - maximum 5000 characters allowed',
      );
    }

    if (entry.krepSeviyesi < 1 || entry.krepSeviyesi > 10) {
      throw Exception(
        'VALIDATION_ERROR: Invalid cringe level - must be between 1-10',
      );
    }

    // User authentication validation
    if (entry.userId.isEmpty || entry.authorName.isEmpty) {
      throw Exception('VALIDATION_ERROR: User authentication data missing');
    }

    // Image validation
    if (entry.imageUrls.isNotEmpty) {
      for (final imageUrl in entry.imageUrls) {
        final isDataUri = imageUrl.startsWith('data:image/');
        final isRemoteUrl = imageUrl.startsWith('http');
        if (imageUrl.isEmpty || (!isDataUri && !isRemoteUrl)) {
          throw Exception('VALIDATION_ERROR: Invalid image format detected');
        }
      }
    }

    print(
      '‚úÖ VALIDATION: All enterprise checks passed (Transaction: $transactionId)',
    );
  }

  // Content analysis and security scanning
  Future<void> _performContentAnalysis(
    CringeEntry entry,
    String transactionId,
  ) async {
    print(
      'üîí SECURITY: Running content analysis and security scan (Transaction: $transactionId)',
    );

    // Geli≈ütirme notu: AI i√ßerik moderasyonu, uygunsuz i√ßerik kontrol√º,
    // spam tespiti ve k√ºf√ºr filtrelemesi i√ßin mod√ºller burada entegre edilecek

    final bannedWords = ['spam', 'hack', 'virus', 'scam'];
    final lowerTitle = entry.baslik.toLowerCase();
    final lowerDesc = entry.aciklama.toLowerCase();

    for (final word in bannedWords) {
      if (lowerTitle.contains(word) || lowerDesc.contains(word)) {
        throw Exception('SECURITY_ERROR: Content contains prohibited terms');
      }
    }

    print(
      '‚úÖ SECURITY: Content approved by enterprise security systems (Transaction: $transactionId)',
    );
  }

  // Prepare enterprise-optimized data
  Future<Map<String, dynamic>> _prepareEnterpriseData(
    CringeEntry entry,
    String transactionId,
  ) async {
    print(
      '‚öôÔ∏è OPTIMIZATION: Preparing enterprise-optimized data structure (Transaction: $transactionId)',
    );

    final processedImages = await _processEnterpriseImages(
      entry,
      transactionId,
    );

    return {
      // Core data
      'userId': entry.userId,
      'authorName': entry.authorName,
      'authorHandle': entry.authorHandle,
      'baslik': entry.baslik.trim(),
      'aciklama': entry.aciklama.trim(),
      'kategori': entry.kategori.index,
      'krepSeviyesi': entry.krepSeviyesi,
      'isAnonim': entry.isAnonim,
      'imageUrls': processedImages,
      'authorAvatarUrl': entry.authorAvatarUrl,
      'etiketler': entry.etiketler,
      'audioUrl': entry.audioUrl,
      'videoUrl': entry.videoUrl,
      'borsaDegeri': entry.borsaDegeri,

      // Timestamps
      'createdAt': FieldValue.serverTimestamp(),
      'updatedAt': FieldValue.serverTimestamp(),

      // Engagement metrics - start fresh
      'begeniSayisi': 0,
      'yorumSayisi': 0,
      'retweetSayisi': 0,
      'goruntulenmeSayisi': 0,

      // Enterprise metadata
      'version': '2.0',
      'source': 'mobile_app',
      'transactionId': transactionId,
      'status': 'active',
      'moderationStatus': 'pending',

      // Analytics data
      'createdAtClient': DateTime.now().toIso8601String(),
      'platform': 'web',
      'deviceInfo': 'enterprise_client',

      // Content metrics
      'titleLength': entry.baslik.length,
      'descriptionLength': entry.aciklama.length,
      'imageCount': processedImages.length,
      'contentHash':
          '${entry.baslik}${entry.aciklama}${processedImages.join(',')}'
              .hashCode
              .toString(),

      // Advanced features
      'trendingScore': 0.0,
      'qualityScore': _calculateQualityScore(entry, processedImages),
      'virality': 0.0,
    };
  }

  // Calculate content quality score
  double _calculateQualityScore(
    CringeEntry entry,
    List<String> processedImages,
  ) {
    double score = 5.0; // Base score

    // Length bonuses
    if (entry.baslik.length >= 20) score += 0.5;
    if (entry.aciklama.length >= 100) score += 1.0;

    // Image bonus
    if (processedImages.isNotEmpty || entry.imageUrls.isNotEmpty) score += 1.5;

    // Cringe level factor
    score += (entry.krepSeviyesi / 10.0) * 2.0;

    return score.clamp(0.0, 10.0);
  }

  Future<List<String>> _processEnterpriseImages(
    CringeEntry entry,
    String transactionId,
  ) async {
    if (entry.imageUrls.isEmpty) {
      return const [];
    }

    final processedUrls = <String>[];

    for (final rawImage in entry.imageUrls) {
      if (rawImage.startsWith('http')) {
        processedUrls.add(rawImage);
        continue;
      }

      if (!rawImage.startsWith('data:image/')) {
        print(
          '‚ö†Ô∏è IMAGE WARN: Unsupported image format received, skipping upload',
        );
        continue;
      }

      try {
        final parts = rawImage.split(',');
        if (parts.length != 2) {
          throw const FormatException('Invalid data URI format');
        }

        final header = parts.first;
        final base64Data = parts.last;
        final mimeType = header.substring(5, header.indexOf(';'));
        final extension = _inferFileExtension(mimeType);
        final bytes = base64Decode(base64Data);
        final Uint8List data = Uint8List.fromList(bytes);

        final storagePath =
            'cringe_entries/${entry.userId}/$transactionId-${DateTime.now().millisecondsSinceEpoch}.$extension';
        final ref = _storage.ref(storagePath);
        final uploadTask = await ref.putData(
          data,
          SettableMetadata(contentType: mimeType),
        );

        final downloadUrl = await uploadTask.ref.getDownloadURL();
        processedUrls.add(downloadUrl);
        print('üñºÔ∏è IMAGE UPLOAD: Stored image at $storagePath');
      } catch (e) {
        print('‚ùå IMAGE UPLOAD ERROR: Failed to process image - $e');
      }
    }

    return processedUrls;
  }

  String _inferFileExtension(String mimeType) {
    switch (mimeType) {
      case 'image/png':
        return 'png';
      case 'image/gif':
        return 'gif';
      case 'image/webp':
        return 'webp';
      case 'image/jpeg':
      case 'image/jpg':
        return 'jpg';
      default:
        return 'jpg';
    }
  }

  // Execute enterprise Firestore transaction
  Future<DocumentReference> _executeEnterpriseTransaction(
    Map<String, dynamic> data,
    String transactionId,
  ) async {
    print(
      'üíæ TRANSACTION: Executing enterprise Firestore transaction (Transaction: $transactionId)',
    );

    try {
      final docRef = await _firestore.collection('cringe_entries').add(data);

      // Additional enterprise operations
      await _updateUserStats(data['userId'], transactionId);
      await _logAuditTrail(docRef.id, data, transactionId);

      return docRef;
    } catch (e) {
      print(
        'üí• TRANSACTION ERROR: Firestore transaction failed (Transaction: $transactionId): $e',
      );
      throw Exception('TRANSACTION_ERROR: Failed to save entry - $e');
    }
  }

  // Post-creation analytics
  Future<void> _performPostCreationAnalytics(
    String entryId,
    CringeEntry entry,
    String transactionId,
  ) async {
    print(
      'üìä ANALYTICS: Running post-creation analytics (Entry: $entryId, Transaction: $transactionId)',
    );

    // Geli≈ütirme notu: Enterprise dashboard, kullanƒ±cƒ± etkile≈üim metrikleri,
    // tavsiye motoru ve trending algoritmalarƒ± buradan tetiklenecek

    print('‚úÖ ANALYTICS: Post-creation analysis completed (Entry: $entryId)');
  }

  // Update user statistics
  Future<void> _updateUserStats(String userId, String transactionId) async {
    try {
      await _firestore.collection('user_stats').doc(userId).set({
        'lastPostAt': FieldValue.serverTimestamp(),
        'totalPosts': FieldValue.increment(1),
        'lastTransactionId': transactionId,
        'lifetimeCringeScore': FieldValue.increment(1),
      }, SetOptions(merge: true));

      print('üìà USER STATS: Updated statistics for user $userId');
    } catch (e) {
      print('‚ö†Ô∏è USER STATS ERROR: Failed to update stats for $userId: $e');
    }
  }

  // Audit trail logging
  Future<void> _logAuditTrail(
    String entryId,
    Map<String, dynamic> data,
    String transactionId,
  ) async {
    try {
      await _firestore.collection('audit_logs').add({
        'action': 'CREATE_ENTRY',
        'entryId': entryId,
        'userId': data['userId'],
        'transactionId': transactionId,
        'timestamp': FieldValue.serverTimestamp(),
        'metadata': {
          'titleLength': data['titleLength'],
          'descriptionLength': data['descriptionLength'],
          'krepSeviyesi': data['krepSeviyesi'],
          'imageCount': data['imageCount'],
          'qualityScore': data['qualityScore'],
        },
      });

      print('üìã AUDIT: Logged creation of entry $entryId');
    } catch (e) {
      print('‚ö†Ô∏è AUDIT ERROR: Failed to log audit trail: $e');
    }
  }

  Future<Map<String, dynamic>> _prepareEnterpriseUpdateData(
    CringeEntry entry,
    String transactionId,
  ) async {
    print(
      'üõ†Ô∏è UPDATE: Preparing enterprise update payload (Entry: ${entry.id}, Transaction: $transactionId)',
    );

    final processedImages = await _processEnterpriseImages(entry, transactionId);

    final payload = <String, dynamic>{
      'authorName': entry.authorName.trim(),
      'authorHandle': entry.authorHandle.trim(),
      'baslik': entry.baslik.trim(),
      'aciklama': entry.aciklama.trim(),
      'kategori': entry.kategori.index,
      'krepSeviyesi': entry.krepSeviyesi,
      'isAnonim': entry.isAnonim,
      'etiketler': entry.etiketler,
      'audioUrl': entry.audioUrl,
      'videoUrl': entry.videoUrl,
      'borsaDegeri': entry.borsaDegeri,
      'authorAvatarUrl': entry.authorAvatarUrl,
      'imageUrls': processedImages,
      'updatedAt': FieldValue.serverTimestamp(),
      'transactionId': transactionId,
      'qualityScore': _calculateQualityScore(entry, processedImages),
      'imageCount': processedImages.length,
    };

    payload.removeWhere((key, value) => value == null);

    return payload;
  }

  Future<void> _logAuditTrailUpdate(
    String entryId,
    String userId,
    Map<String, dynamic> updateData,
    String transactionId,
  ) async {
    try {
      await _firestore.collection('audit_logs').add({
        'action': 'UPDATE_ENTRY',
        'entryId': entryId,
        'userId': userId,
        'transactionId': transactionId,
        'timestamp': FieldValue.serverTimestamp(),
        'metadata': {
          'updatedFields': updateData.keys.toList(),
          'imageCount': updateData['imageCount'] ?? 0,
          'qualityScore': updateData['qualityScore'],
        },
      });

      print('üìã AUDIT: Logged update of entry $entryId');
    } catch (e) {
      print('‚ö†Ô∏è AUDIT ERROR: Failed to log update for $entryId: $e');
    }
  }

  Future<void> _logAuditTrailDelete(
    String entryId,
    String userId,
    String transactionId,
  ) async {
    try {
      await _firestore.collection('audit_logs').add({
        'action': 'DELETE_ENTRY',
        'entryId': entryId,
        'userId': userId,
        'transactionId': transactionId,
        'timestamp': FieldValue.serverTimestamp(),
      });

      print('üìã AUDIT: Logged deletion of entry $entryId');
    } catch (e) {
      print('‚ö†Ô∏è AUDIT ERROR: Failed to log delete audit for $entryId: $e');
    }
  }

  Future<void> _decrementUserStats(
    String userId,
    String transactionId,
  ) async {
    try {
      await _firestore.collection('user_stats').doc(userId).set({
        'totalPosts': FieldValue.increment(-1),
        'lifetimeCringeScore': FieldValue.increment(-1),
        'lastTransactionId': transactionId,
        'lastPostAt': FieldValue.serverTimestamp(),
      }, SetOptions(merge: true));

      print('üìâ USER STATS: Decremented statistics for user $userId');
    } catch (e) {
      print('‚ö†Ô∏è USER STATS ERROR: Failed to decrement stats for $userId: $e');
    }
  }

  // Enterprise error handling
  Future<void> _handleEnterpriseAddError(
    dynamic error,
    CringeEntry entry,
    String transactionId,
  ) async {
    print(
      'üö® ERROR HANDLER: Processing enterprise add error (Transaction: $transactionId)',
    );

    try {
      // Log error to enterprise monitoring
      await _firestore.collection('error_logs').add({
        'error': error.toString(),
        'transactionId': transactionId,
        'userId': entry.userId,
        'action': 'ADD_ENTRY',
        'timestamp': FieldValue.serverTimestamp(),
        'severity': 'HIGH',
        'context': {
          'title': entry.baslik,
          'titleLength': entry.baslik.length,
          'descriptionLength': entry.aciklama.length,
          'imageCount': entry.imageUrls.length,
        },
      });

      print('üìù ERROR LOGGED: Enterprise error logging completed');
    } catch (e) {
      print('üí• CRITICAL: Failed to log error to enterprise systems: $e');
    }
  }

  // Enterprise notifications
  void _triggerEnterpriseNotifications(String entryId, CringeEntry entry) {
    // Planlanan √ßalƒ±≈ümalar: push bildirimleri, y√ºksek cringe seviyeleri i√ßin e-posta,
    // i√ßerik inceleme uyarƒ±larƒ± ve takip√ßilere ger√ßek zamanlƒ± bildirimler

    print(
      'üîî NOTIFICATIONS: Enterprise notification system triggered for entry $entryId',
    );
    print(
      'üì± PUSH: High cringe level detected (${entry.krepSeviyesi}/10) - triggering viral alerts',
    );
  }

  // Entry'yi beƒüen
  Future<bool> likeEntry(String entryId) async {
    try {
      if (_auth.currentUser == null) return false;

      await _firestore.collection('cringe_entries').doc(entryId).update({
        'likes': FieldValue.increment(1),
      });

      return true;
    } catch (e) {
      print('Like entry error: $e');
      return false;
    }
  }

  Future<bool> updateEntry(CringeEntry entry) async {
    final currentUserId = _auth.currentUser?.uid;
    if (currentUserId == null) {
      throw StateError('NOT_AUTHENTICATED: Kullanƒ±cƒ± oturumu bulunamadƒ±');
    }

    final docRef = _firestore.collection('cringe_entries').doc(entry.id);
    final snapshot = await docRef.get();
    if (!snapshot.exists) {
      return false;
    }

    final ownerId = snapshot.data()?['userId'] as String? ?? '';
    if (ownerId != currentUserId) {
      throw StateError('NOT_AUTHORIZED: Bu krepi d√ºzenleme yetkin yok');
    }

    final transactionId =
        'upd_${DateTime.now().millisecondsSinceEpoch.toString()}';
    final updateData = await _prepareEnterpriseUpdateData(
      entry.copyWith(userId: currentUserId),
      transactionId,
    );

    await docRef.update(updateData);
    await _logAuditTrailUpdate(entry.id, currentUserId, updateData, transactionId);

    return true;
  }

  Future<bool> deleteEntry(String entryId) async {
    final currentUserId = _auth.currentUser?.uid;
    if (currentUserId == null) {
      throw StateError('NOT_AUTHENTICATED: Kullanƒ±cƒ± oturumu bulunamadƒ±');
    }

    final docRef = _firestore.collection('cringe_entries').doc(entryId);
    final snapshot = await docRef.get();
    if (!snapshot.exists) {
      return false;
    }

    final ownerId = snapshot.data()?['userId'] as String? ?? '';
    if (ownerId != currentUserId) {
      throw StateError('NOT_AUTHORIZED: Bu krepi silme yetkin yok');
    }

    final transactionId =
        'del_${DateTime.now().millisecondsSinceEpoch.toString()}';

    await docRef.delete();
    await _decrementUserStats(currentUserId, transactionId);
    await _logAuditTrailDelete(entryId, currentUserId, transactionId);

    return true;
  }
}
